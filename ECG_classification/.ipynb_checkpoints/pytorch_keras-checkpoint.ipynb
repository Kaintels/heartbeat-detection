{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 라이브러리\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 전처리에 필요한 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 777\n",
    "batch_sizes = 16\n",
    "x_train_st = []\n",
    "x_test_st = []\n",
    "y_train_st = []\n",
    "y_test_st = []\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "# 데이터 불러오기\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리, 심전도 신호를 3 beat 씩 자른뒤, 레이블 3개가 모두 정상일 경우 정상, 이외에는 비정상으로 구성\n",
    "\n",
    "\n",
    "for i in range(len(x_train) - 2):\n",
    "    data = np.hstack((x_train[i], x_train[i + 1], x_train[i + 2]))\n",
    "    x_train_st.append(data)\n",
    "\n",
    "x_train_st = np.array(x_train_st)\n",
    "\n",
    "for i in range(len(x_test) - 2):\n",
    "    data = np.hstack((x_test[i], x_test[i + 1], x_test[i + 2]))\n",
    "    x_test_st.append(data)\n",
    "\n",
    "x_test_st = np.array(x_test_st)\n",
    "\n",
    "x_train = x_train_st[:, :, np.newaxis]\n",
    "x_test = x_test_st[:, :, np.newaxis]\n",
    "#\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "for i in range(len(y_train) - 2):\n",
    "    data = np.hstack((y_train[i], y_train[i + 1], y_train[i + 2]))\n",
    "    y_train_st.append(data)\n",
    "\n",
    "y_train_st = np.array(y_train_st)\n",
    "\n",
    "for i in range(len(y_test) - 2):\n",
    "    data = np.hstack((y_test[i], y_test[i + 1], y_test[i + 2]))\n",
    "    y_test_st.append(data)\n",
    "\n",
    "y_test_st = np.array(y_test_st)\n",
    "\n",
    "for i in range(len(y_test_st)):\n",
    "    if sum(y_test_st[i]) == 0:\n",
    "        y_test_st[i] = [0]\n",
    "    else:\n",
    "        y_test_st[i] = [1]\n",
    "\n",
    "for i in range(len(y_train_st)):\n",
    "    if sum(y_train_st[i]) == 0:\n",
    "        y_train_st[i] = [0]\n",
    "    else:\n",
    "        y_train_st[i] = [1]\n",
    "\n",
    "y_train = y_train_st[0:len(y_train_st), 0:1]\n",
    "y_test = y_test_st[0:len(y_test_st), 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).float().permute(0, 2, 1)\n",
    "x_test = torch.from_numpy(x_test).float().permute(0, 2, 1)\n",
    "\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "train = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train, batch_size=batch_sizes, shuffle=True)\n",
    "test = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test, batch_size=batch_sizes, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DetectionNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, padding_mode='zeros', padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding_mode='zeros', padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding_mode='zeros', padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding_mode='zeros', padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding_mode='zeros', padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding_mode='zeros', padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=3, padding_mode='zeros', padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding_mode='zeros', padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=256, out_channels=256, kernel_size=3, padding_mode='zeros', padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "        )\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.LSTM(3, 64, 1)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16384, 2),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, out):\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out, _ = self.layer10(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  # if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = DetectionNet().to(device)\n",
    "num_epochs = 1\n",
    "from torchsummaryX import summary\n",
    "\n",
    "summary(model, torch.zeros(16, 1, 510).to(device))\n",
    "\n",
    "print(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x_train, y_train) in enumerate(train_loader):\n",
    "        x_train = x_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(x_train)\n",
    "        loss = criterion(outputs, y_train.squeeze())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % batch_sizes == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x_test, y_test in test_loader:\n",
    "        x_test = x_test.to(device)\n",
    "        y_test = y_test.to(device)\n",
    "\n",
    "        outputs = model(x_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.squeeze()).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model: {} %'.format(100 * correct / total))\n",
    "    print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 케라스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Bidirectional\n",
    "from tensorflow.keras.layers import Flatten, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, GRU, LSTM, Activation\n",
    "from tensorflow.keras.layers import MaxPooling1D, Softmax, AveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 고정\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tests = to_categorical(y_test, 2)\n",
    "y_trains = to_categorical(y_train, 2)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=32, padding='same', kernel_size=3, input_shape=(510,1), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters=32, padding='same', kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters=64, padding='same', kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters=64, padding='same', kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters=128, padding='same', kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters=128, padding='same', kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters=256, padding='same', kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters=256, padding='same', kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=64, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy',  metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_trains, shuffle=True, batch_size=batch_sizes, epochs=1,verbose=1)\n",
    "history_dict = history.history\n",
    "loss, accuracy = model.evaluate(x_test, y_tests, verbose=1, batch_size=batch_sizes)\n",
    "pred = model.predict(x_test, batch_size=batch_sizes, verbose=1)\n",
    "predicted_classes = np.argmax(pred, axis=1)\n",
    "target_names = ['Non-ectopic', 'Ectopic']\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predicted_classes,target_names=target_names, digits = 6))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predicted_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
